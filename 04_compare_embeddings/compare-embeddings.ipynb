{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare embeddings performance\n",
    "\n",
    "We use different approaches to create embeddings from the same texts and compare their performance.\n",
    "\n",
    "## Configuration:\n",
    "\n",
    "Please select the model you want to use for the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "llm_source = \"openai\" # openai or hf for huggingface\n",
    "embedding_source = \"openai\" # openai or hf for huggingface\n",
    "\n",
    "llm_model = \"gpt-4o\"\n",
    "temperature = 0\n",
    "\n",
    "embeddings_model = \"text-embedding-ada-002\"\n",
    "\n",
    "markdown_documents_path = \"C:\\\\Dev\\\\tt\\\\tt-readme\"\n",
    "\n",
    "use_cached_documents = True\n",
    "use_cached_transforms = True\n",
    "reindex_documents = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different approaches of indexing\n",
    "\n",
    "This will\n",
    "- create a question for each document,\n",
    "- create an answer for each document and\n",
    "- summarize each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split markdown contents of the TT Readme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "if use_cached_documents:\n",
    "    print(\"Skipping loading documents from markdown files\")\n",
    "else:\n",
    "\n",
    "    from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "    from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "    readme_documents = DirectoryLoader(\n",
    "        markdown_documents_path,\n",
    "        glob=\"**/*.md\",\n",
    "        loader_cls=TextLoader\n",
    "        ).load()\n",
    "\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "    ]\n",
    "\n",
    "    splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "\n",
    "    split_documents = []\n",
    "    for doc in readme_documents:\n",
    "        result = splitter.split_text(doc.page_content)\n",
    "\n",
    "        if isinstance(result, list):\n",
    "            for res in result:\n",
    "                res.metadata.update(doc.metadata)\n",
    "            split_documents.extend(result)\n",
    "        else:\n",
    "            result.metadata.update(doc.metadata)\n",
    "            split_documents.append(result)\n",
    "\n",
    "    # For brevity, reduce amount of entries to a few only\n",
    "    # split_documents = split_documents[50:60]\n",
    "\n",
    "    index  = 1\n",
    "    for doc in split_documents:\n",
    "        doc.metadata[\"index\"] = index\n",
    "        index += 1\n",
    "        doc.metadata[\"original_content\"] = doc.page_content\n",
    "        #print(doc.metadata)\n",
    "        #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the data to files or load cached files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing documents to file\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if (use_cached_documents):\n",
    "    print(\"Loading documents from file\")\n",
    "    with open(\"cache/split_documents.pickle\", \"rb\") as f:\n",
    "        split_documents = pickle.load(f)\n",
    "else:\n",
    "    print(\"Writing documents to file\")\n",
    "    with open(\"cache/split_documents.pickle\", \"wb\") as f:\n",
    "        pickle.dump(split_documents, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massage content into new embedding documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=llm_model, temperature=temperature)\n",
    "\n",
    "def build_chain(prompt):\n",
    "    return LLMChain(llm=llm, prompt=PromptTemplate(input_variables=[\"input\"], template=prompt))\n",
    "\n",
    "question_chain = build_chain(\"Formuliere drei verschiedene deutsche Fragen, die der folgende Text beantwortet: {input}\")\n",
    "answer_chain = build_chain(\"Erkläre in zwei bis drei deutschen Sätzen, was der folgende Text beantwortet: {input}\")\n",
    "summarize_chain = build_chain(\"Erstelle eine kurze deutsche Zusammenfassung des folgenden Textes: {input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming questions document 1 with model gpt-4o\n",
      "Transforming questions document 2 with model gpt-4o\n",
      "Transforming questions document 3 with model gpt-4o\n",
      "Transforming questions document 4 with model gpt-4o\n",
      "Transforming questions document 5 with model gpt-4o\n",
      "Transforming questions document 6 with model gpt-4o\n",
      "Transforming questions document 7 with model gpt-4o\n",
      "Transforming questions document 8 with model gpt-4o\n",
      "Transforming questions document 9 with model gpt-4o\n",
      "Transforming questions document 10 with model gpt-4o\n",
      "Transforming questions document 11 with model gpt-4o\n",
      "Transforming questions document 12 with model gpt-4o\n",
      "Transforming questions document 13 with model gpt-4o\n",
      "Transforming questions document 14 with model gpt-4o\n",
      "Transforming questions document 15 with model gpt-4o\n",
      "Transforming questions document 16 with model gpt-4o\n",
      "Transforming questions document 17 with model gpt-4o\n",
      "Transforming questions document 18 with model gpt-4o\n",
      "Transforming questions document 19 with model gpt-4o\n",
      "Transforming questions document 20 with model gpt-4o\n",
      "Transforming questions document 21 with model gpt-4o\n",
      "Transforming questions document 22 with model gpt-4o\n",
      "Transforming questions document 23 with model gpt-4o\n",
      "Transforming questions document 24 with model gpt-4o\n",
      "Transforming questions document 25 with model gpt-4o\n",
      "Transforming questions document 26 with model gpt-4o\n",
      "Transforming questions document 27 with model gpt-4o\n",
      "Transforming questions document 28 with model gpt-4o\n",
      "Transforming questions document 29 with model gpt-4o\n",
      "Transforming questions document 30 with model gpt-4o\n",
      "Transforming questions document 31 with model gpt-4o\n",
      "Transforming questions document 32 with model gpt-4o\n",
      "Transforming questions document 33 with model gpt-4o\n",
      "Transforming questions document 34 with model gpt-4o\n",
      "Transforming questions document 35 with model gpt-4o\n",
      "Transforming questions document 36 with model gpt-4o\n",
      "Transforming questions document 37 with model gpt-4o\n",
      "Transforming questions document 38 with model gpt-4o\n",
      "Transforming questions document 39 with model gpt-4o\n",
      "Transforming questions document 40 with model gpt-4o\n",
      "Transforming questions document 41 with model gpt-4o\n",
      "Transforming questions document 42 with model gpt-4o\n",
      "Transforming questions document 43 with model gpt-4o\n",
      "Transforming questions document 44 with model gpt-4o\n",
      "Transforming questions document 45 with model gpt-4o\n",
      "Transforming questions document 46 with model gpt-4o\n",
      "Transforming questions document 47 with model gpt-4o\n",
      "Transforming questions document 48 with model gpt-4o\n",
      "Transforming questions document 49 with model gpt-4o\n",
      "Transforming questions document 50 with model gpt-4o\n",
      "Transforming questions document 51 with model gpt-4o\n",
      "Transforming questions document 52 with model gpt-4o\n",
      "Transforming questions document 53 with model gpt-4o\n",
      "Transforming questions document 54 with model gpt-4o\n",
      "Transforming questions document 55 with model gpt-4o\n",
      "Transforming questions document 56 with model gpt-4o\n",
      "Transforming questions document 57 with model gpt-4o\n",
      "Transforming questions document 58 with model gpt-4o\n",
      "Transforming questions document 59 with model gpt-4o\n",
      "Transforming questions document 60 with model gpt-4o\n",
      "Transforming questions document 61 with model gpt-4o\n",
      "Transforming questions document 62 with model gpt-4o\n",
      "Transforming questions document 63 with model gpt-4o\n",
      "Transforming questions document 64 with model gpt-4o\n",
      "Transforming questions document 65 with model gpt-4o\n",
      "Transforming questions document 66 with model gpt-4o\n",
      "Transforming questions document 67 with model gpt-4o\n",
      "Transforming questions document 68 with model gpt-4o\n",
      "Transforming questions document 69 with model gpt-4o\n",
      "Transforming questions document 70 with model gpt-4o\n",
      "Transforming questions document 71 with model gpt-4o\n",
      "Transforming questions document 72 with model gpt-4o\n",
      "Transforming questions document 73 with model gpt-4o\n",
      "Transforming questions document 74 with model gpt-4o\n",
      "Transforming questions document 75 with model gpt-4o\n",
      "Transforming questions document 76 with model gpt-4o\n",
      "Transforming questions document 77 with model gpt-4o\n",
      "Transforming questions document 78 with model gpt-4o\n",
      "Transforming questions document 79 with model gpt-4o\n",
      "Transforming questions document 80 with model gpt-4o\n",
      "Transforming questions document 81 with model gpt-4o\n",
      "Transforming questions document 82 with model gpt-4o\n",
      "Transforming questions document 83 with model gpt-4o\n",
      "Transforming questions document 84 with model gpt-4o\n",
      "Transforming questions document 85 with model gpt-4o\n",
      "Transforming questions document 86 with model gpt-4o\n",
      "Transforming questions document 87 with model gpt-4o\n",
      "Transforming questions document 88 with model gpt-4o\n",
      "Transforming questions document 89 with model gpt-4o\n",
      "Transforming questions document 90 with model gpt-4o\n",
      "Transforming questions document 91 with model gpt-4o\n",
      "Transforming questions document 92 with model gpt-4o\n",
      "Transforming questions document 93 with model gpt-4o\n",
      "Transforming questions document 94 with model gpt-4o\n",
      "Transforming questions document 95 with model gpt-4o\n",
      "Transforming questions document 96 with model gpt-4o\n",
      "Transforming questions document 97 with model gpt-4o\n",
      "Transforming questions document 98 with model gpt-4o\n",
      "Transforming questions document 99 with model gpt-4o\n",
      "Transforming questions document 100 with model gpt-4o\n",
      "Transforming questions document 101 with model gpt-4o\n",
      "Transforming questions document 102 with model gpt-4o\n",
      "Transforming questions document 103 with model gpt-4o\n",
      "Transforming questions document 104 with model gpt-4o\n",
      "Transforming questions document 105 with model gpt-4o\n",
      "Transforming questions document 106 with model gpt-4o\n",
      "Transforming questions document 107 with model gpt-4o\n",
      "Transforming questions document 108 with model gpt-4o\n",
      "Transforming questions document 109 with model gpt-4o\n",
      "Transforming questions document 110 with model gpt-4o\n",
      "Transforming questions document 111 with model gpt-4o\n",
      "Transforming questions document 112 with model gpt-4o\n",
      "Transforming questions document 113 with model gpt-4o\n",
      "Transforming questions document 114 with model gpt-4o\n",
      "Transforming questions document 115 with model gpt-4o\n",
      "Transforming questions document 116 with model gpt-4o\n",
      "Transforming questions document 117 with model gpt-4o\n",
      "Transforming questions document 118 with model gpt-4o\n",
      "Transforming questions document 119 with model gpt-4o\n",
      "Transforming questions document 120 with model gpt-4o\n",
      "Transforming questions document 121 with model gpt-4o\n",
      "Transforming questions document 122 with model gpt-4o\n",
      "Transforming questions document 123 with model gpt-4o\n",
      "Transforming questions document 124 with model gpt-4o\n",
      "Transforming questions document 125 with model gpt-4o\n",
      "Transforming questions document 126 with model gpt-4o\n",
      "Transforming questions document 127 with model gpt-4o\n",
      "Transforming questions document 128 with model gpt-4o\n",
      "Transforming questions document 129 with model gpt-4o\n",
      "Transforming questions document 130 with model gpt-4o\n",
      "Transforming questions document 131 with model gpt-4o\n",
      "Transforming questions document 132 with model gpt-4o\n",
      "Transforming questions document 133 with model gpt-4o\n",
      "Transforming questions document 134 with model gpt-4o\n",
      "Transforming questions document 135 with model gpt-4o\n",
      "Transforming questions document 136 with model gpt-4o\n",
      "Transforming questions document 137 with model gpt-4o\n",
      "Transforming questions document 138 with model gpt-4o\n",
      "Transforming questions document 139 with model gpt-4o\n",
      "Transforming questions document 140 with model gpt-4o\n",
      "Transforming questions document 141 with model gpt-4o\n",
      "Transforming questions document 142 with model gpt-4o\n",
      "Transforming questions document 143 with model gpt-4o\n",
      "Transforming questions document 144 with model gpt-4o\n",
      "Transforming questions document 145 with model gpt-4o\n",
      "Transforming questions document 146 with model gpt-4o\n",
      "Transforming questions document 147 with model gpt-4o\n",
      "Transforming questions document 148 with model gpt-4o\n",
      "Transforming questions document 149 with model gpt-4o\n",
      "Transforming questions document 150 with model gpt-4o\n",
      "Transforming questions document 151 with model gpt-4o\n",
      "Transforming questions document 152 with model gpt-4o\n",
      "Transforming questions document 153 with model gpt-4o\n",
      "Transforming questions document 154 with model gpt-4o\n",
      "Transforming questions document 155 with model gpt-4o\n",
      "Transforming questions document 156 with model gpt-4o\n",
      "Transforming questions document 157 with model gpt-4o\n",
      "Transforming questions document 158 with model gpt-4o\n",
      "Transforming questions document 159 with model gpt-4o\n",
      "Transforming questions document 160 with model gpt-4o\n",
      "Transforming questions document 161 with model gpt-4o\n",
      "Transforming questions document 162 with model gpt-4o\n",
      "Transforming questions document 163 with model gpt-4o\n",
      "Transforming questions document 164 with model gpt-4o\n",
      "Transforming questions document 165 with model gpt-4o\n",
      "Transforming questions document 166 with model gpt-4o\n",
      "Transforming questions document 167 with model gpt-4o\n",
      "Transforming questions document 168 with model gpt-4o\n",
      "Transforming questions document 169 with model gpt-4o\n",
      "Transforming questions document 170 with model gpt-4o\n",
      "Transforming questions document 171 with model gpt-4o\n",
      "Transforming questions document 172 with model gpt-4o\n",
      "Transforming questions document 173 with model gpt-4o\n",
      "Transforming questions document 174 with model gpt-4o\n",
      "Transforming questions document 175 with model gpt-4o\n",
      "Transforming questions document 176 with model gpt-4o\n",
      "Transforming questions document 177 with model gpt-4o\n",
      "Transforming questions document 178 with model gpt-4o\n",
      "Transforming questions document 179 with model gpt-4o\n",
      "Writing questions documents from model gpt-4o to file\n",
      "Transforming answers document 1 with model gpt-4o\n",
      "Transforming answers document 2 with model gpt-4o\n",
      "Transforming answers document 3 with model gpt-4o\n",
      "Transforming answers document 4 with model gpt-4o\n",
      "Transforming answers document 5 with model gpt-4o\n",
      "Transforming answers document 6 with model gpt-4o\n",
      "Transforming answers document 7 with model gpt-4o\n",
      "Transforming answers document 8 with model gpt-4o\n",
      "Transforming answers document 9 with model gpt-4o\n",
      "Transforming answers document 10 with model gpt-4o\n",
      "Transforming answers document 11 with model gpt-4o\n",
      "Transforming answers document 12 with model gpt-4o\n",
      "Transforming answers document 13 with model gpt-4o\n",
      "Transforming answers document 14 with model gpt-4o\n",
      "Transforming answers document 15 with model gpt-4o\n",
      "Transforming answers document 16 with model gpt-4o\n",
      "Transforming answers document 17 with model gpt-4o\n",
      "Transforming answers document 18 with model gpt-4o\n",
      "Transforming answers document 19 with model gpt-4o\n",
      "Transforming answers document 20 with model gpt-4o\n",
      "Transforming answers document 21 with model gpt-4o\n",
      "Transforming answers document 22 with model gpt-4o\n",
      "Transforming answers document 23 with model gpt-4o\n",
      "Transforming answers document 24 with model gpt-4o\n",
      "Transforming answers document 25 with model gpt-4o\n",
      "Transforming answers document 26 with model gpt-4o\n",
      "Transforming answers document 27 with model gpt-4o\n",
      "Transforming answers document 28 with model gpt-4o\n",
      "Transforming answers document 29 with model gpt-4o\n",
      "Transforming answers document 30 with model gpt-4o\n",
      "Transforming answers document 31 with model gpt-4o\n",
      "Transforming answers document 32 with model gpt-4o\n",
      "Transforming answers document 33 with model gpt-4o\n",
      "Transforming answers document 34 with model gpt-4o\n",
      "Transforming answers document 35 with model gpt-4o\n",
      "Transforming answers document 36 with model gpt-4o\n",
      "Transforming answers document 37 with model gpt-4o\n",
      "Transforming answers document 38 with model gpt-4o\n",
      "Transforming answers document 39 with model gpt-4o\n",
      "Transforming answers document 40 with model gpt-4o\n",
      "Transforming answers document 41 with model gpt-4o\n",
      "Transforming answers document 42 with model gpt-4o\n",
      "Transforming answers document 43 with model gpt-4o\n",
      "Transforming answers document 44 with model gpt-4o\n",
      "Transforming answers document 45 with model gpt-4o\n",
      "Transforming answers document 46 with model gpt-4o\n",
      "Transforming answers document 47 with model gpt-4o\n",
      "Transforming answers document 48 with model gpt-4o\n",
      "Transforming answers document 49 with model gpt-4o\n",
      "Transforming answers document 50 with model gpt-4o\n",
      "Transforming answers document 51 with model gpt-4o\n",
      "Transforming answers document 52 with model gpt-4o\n",
      "Transforming answers document 53 with model gpt-4o\n",
      "Transforming answers document 54 with model gpt-4o\n",
      "Transforming answers document 55 with model gpt-4o\n",
      "Transforming answers document 56 with model gpt-4o\n",
      "Transforming answers document 57 with model gpt-4o\n",
      "Transforming answers document 58 with model gpt-4o\n",
      "Transforming answers document 59 with model gpt-4o\n",
      "Transforming answers document 60 with model gpt-4o\n",
      "Transforming answers document 61 with model gpt-4o\n",
      "Transforming answers document 62 with model gpt-4o\n",
      "Transforming answers document 63 with model gpt-4o\n",
      "Transforming answers document 64 with model gpt-4o\n",
      "Transforming answers document 65 with model gpt-4o\n",
      "Transforming answers document 66 with model gpt-4o\n",
      "Transforming answers document 67 with model gpt-4o\n",
      "Transforming answers document 68 with model gpt-4o\n",
      "Transforming answers document 69 with model gpt-4o\n",
      "Transforming answers document 70 with model gpt-4o\n",
      "Transforming answers document 71 with model gpt-4o\n",
      "Transforming answers document 72 with model gpt-4o\n",
      "Transforming answers document 73 with model gpt-4o\n",
      "Transforming answers document 74 with model gpt-4o\n",
      "Transforming answers document 75 with model gpt-4o\n",
      "Transforming answers document 76 with model gpt-4o\n",
      "Transforming answers document 77 with model gpt-4o\n",
      "Transforming answers document 78 with model gpt-4o\n",
      "Transforming answers document 79 with model gpt-4o\n",
      "Transforming answers document 80 with model gpt-4o\n",
      "Transforming answers document 81 with model gpt-4o\n",
      "Transforming answers document 82 with model gpt-4o\n",
      "Transforming answers document 83 with model gpt-4o\n",
      "Transforming answers document 84 with model gpt-4o\n",
      "Transforming answers document 85 with model gpt-4o\n",
      "Transforming answers document 86 with model gpt-4o\n",
      "Transforming answers document 87 with model gpt-4o\n",
      "Transforming answers document 88 with model gpt-4o\n",
      "Transforming answers document 89 with model gpt-4o\n",
      "Transforming answers document 90 with model gpt-4o\n",
      "Transforming answers document 91 with model gpt-4o\n",
      "Transforming answers document 92 with model gpt-4o\n",
      "Transforming answers document 93 with model gpt-4o\n",
      "Transforming answers document 94 with model gpt-4o\n",
      "Transforming answers document 95 with model gpt-4o\n",
      "Transforming answers document 96 with model gpt-4o\n",
      "Transforming answers document 97 with model gpt-4o\n",
      "Transforming answers document 98 with model gpt-4o\n",
      "Transforming answers document 99 with model gpt-4o\n",
      "Transforming answers document 100 with model gpt-4o\n",
      "Transforming answers document 101 with model gpt-4o\n",
      "Transforming answers document 102 with model gpt-4o\n",
      "Transforming answers document 103 with model gpt-4o\n",
      "Transforming answers document 104 with model gpt-4o\n",
      "Transforming answers document 105 with model gpt-4o\n",
      "Transforming answers document 106 with model gpt-4o\n",
      "Transforming answers document 107 with model gpt-4o\n",
      "Transforming answers document 108 with model gpt-4o\n",
      "Transforming answers document 109 with model gpt-4o\n",
      "Transforming answers document 110 with model gpt-4o\n",
      "Transforming answers document 111 with model gpt-4o\n",
      "Transforming answers document 112 with model gpt-4o\n",
      "Transforming answers document 113 with model gpt-4o\n",
      "Transforming answers document 114 with model gpt-4o\n",
      "Transforming answers document 115 with model gpt-4o\n",
      "Transforming answers document 116 with model gpt-4o\n",
      "Transforming answers document 117 with model gpt-4o\n",
      "Transforming answers document 118 with model gpt-4o\n",
      "Transforming answers document 119 with model gpt-4o\n",
      "Transforming answers document 120 with model gpt-4o\n",
      "Transforming answers document 121 with model gpt-4o\n",
      "Transforming answers document 122 with model gpt-4o\n",
      "Transforming answers document 123 with model gpt-4o\n",
      "Transforming answers document 124 with model gpt-4o\n",
      "Transforming answers document 125 with model gpt-4o\n",
      "Transforming answers document 126 with model gpt-4o\n",
      "Transforming answers document 127 with model gpt-4o\n",
      "Transforming answers document 128 with model gpt-4o\n",
      "Transforming answers document 129 with model gpt-4o\n",
      "Transforming answers document 130 with model gpt-4o\n",
      "Transforming answers document 131 with model gpt-4o\n",
      "Transforming answers document 132 with model gpt-4o\n",
      "Transforming answers document 133 with model gpt-4o\n",
      "Transforming answers document 134 with model gpt-4o\n",
      "Transforming answers document 135 with model gpt-4o\n",
      "Transforming answers document 136 with model gpt-4o\n",
      "Transforming answers document 137 with model gpt-4o\n",
      "Transforming answers document 138 with model gpt-4o\n",
      "Transforming answers document 139 with model gpt-4o\n",
      "Transforming answers document 140 with model gpt-4o\n",
      "Transforming answers document 141 with model gpt-4o\n",
      "Transforming answers document 142 with model gpt-4o\n",
      "Transforming answers document 143 with model gpt-4o\n",
      "Transforming answers document 144 with model gpt-4o\n",
      "Transforming answers document 145 with model gpt-4o\n",
      "Transforming answers document 146 with model gpt-4o\n",
      "Transforming answers document 147 with model gpt-4o\n",
      "Transforming answers document 148 with model gpt-4o\n",
      "Transforming answers document 149 with model gpt-4o\n",
      "Transforming answers document 150 with model gpt-4o\n",
      "Transforming answers document 151 with model gpt-4o\n",
      "Transforming answers document 152 with model gpt-4o\n",
      "Transforming answers document 153 with model gpt-4o\n",
      "Transforming answers document 154 with model gpt-4o\n",
      "Transforming answers document 155 with model gpt-4o\n",
      "Transforming answers document 156 with model gpt-4o\n",
      "Transforming answers document 157 with model gpt-4o\n",
      "Transforming answers document 158 with model gpt-4o\n",
      "Transforming answers document 159 with model gpt-4o\n",
      "Transforming answers document 160 with model gpt-4o\n",
      "Transforming answers document 161 with model gpt-4o\n",
      "Transforming answers document 162 with model gpt-4o\n",
      "Transforming answers document 163 with model gpt-4o\n",
      "Transforming answers document 164 with model gpt-4o\n",
      "Transforming answers document 165 with model gpt-4o\n",
      "Transforming answers document 166 with model gpt-4o\n",
      "Transforming answers document 167 with model gpt-4o\n",
      "Transforming answers document 168 with model gpt-4o\n",
      "Transforming answers document 169 with model gpt-4o\n",
      "Transforming answers document 170 with model gpt-4o\n",
      "Transforming answers document 171 with model gpt-4o\n",
      "Transforming answers document 172 with model gpt-4o\n",
      "Transforming answers document 173 with model gpt-4o\n",
      "Transforming answers document 174 with model gpt-4o\n",
      "Transforming answers document 175 with model gpt-4o\n",
      "Transforming answers document 176 with model gpt-4o\n",
      "Transforming answers document 177 with model gpt-4o\n",
      "Transforming answers document 178 with model gpt-4o\n",
      "Transforming answers document 179 with model gpt-4o\n",
      "Writing answers documents from model gpt-4o to file\n",
      "Transforming summaries document 1 with model gpt-4o\n",
      "Transforming summaries document 2 with model gpt-4o\n",
      "Transforming summaries document 3 with model gpt-4o\n",
      "Transforming summaries document 4 with model gpt-4o\n",
      "Transforming summaries document 5 with model gpt-4o\n",
      "Transforming summaries document 6 with model gpt-4o\n",
      "Transforming summaries document 7 with model gpt-4o\n",
      "Transforming summaries document 8 with model gpt-4o\n",
      "Transforming summaries document 9 with model gpt-4o\n",
      "Transforming summaries document 10 with model gpt-4o\n",
      "Transforming summaries document 11 with model gpt-4o\n",
      "Transforming summaries document 12 with model gpt-4o\n",
      "Transforming summaries document 13 with model gpt-4o\n",
      "Transforming summaries document 14 with model gpt-4o\n",
      "Transforming summaries document 15 with model gpt-4o\n",
      "Transforming summaries document 16 with model gpt-4o\n",
      "Transforming summaries document 17 with model gpt-4o\n",
      "Transforming summaries document 18 with model gpt-4o\n",
      "Transforming summaries document 19 with model gpt-4o\n",
      "Transforming summaries document 20 with model gpt-4o\n",
      "Transforming summaries document 21 with model gpt-4o\n",
      "Transforming summaries document 22 with model gpt-4o\n",
      "Transforming summaries document 23 with model gpt-4o\n",
      "Transforming summaries document 24 with model gpt-4o\n",
      "Transforming summaries document 25 with model gpt-4o\n",
      "Transforming summaries document 26 with model gpt-4o\n",
      "Transforming summaries document 27 with model gpt-4o\n",
      "Transforming summaries document 28 with model gpt-4o\n",
      "Transforming summaries document 29 with model gpt-4o\n",
      "Transforming summaries document 30 with model gpt-4o\n",
      "Transforming summaries document 31 with model gpt-4o\n",
      "Transforming summaries document 32 with model gpt-4o\n",
      "Transforming summaries document 33 with model gpt-4o\n",
      "Transforming summaries document 34 with model gpt-4o\n",
      "Transforming summaries document 35 with model gpt-4o\n",
      "Transforming summaries document 36 with model gpt-4o\n",
      "Transforming summaries document 37 with model gpt-4o\n",
      "Transforming summaries document 38 with model gpt-4o\n",
      "Transforming summaries document 39 with model gpt-4o\n",
      "Transforming summaries document 40 with model gpt-4o\n",
      "Transforming summaries document 41 with model gpt-4o\n",
      "Transforming summaries document 42 with model gpt-4o\n",
      "Transforming summaries document 43 with model gpt-4o\n",
      "Transforming summaries document 44 with model gpt-4o\n",
      "Transforming summaries document 45 with model gpt-4o\n",
      "Transforming summaries document 46 with model gpt-4o\n",
      "Transforming summaries document 47 with model gpt-4o\n",
      "Transforming summaries document 48 with model gpt-4o\n",
      "Transforming summaries document 49 with model gpt-4o\n",
      "Transforming summaries document 50 with model gpt-4o\n",
      "Transforming summaries document 51 with model gpt-4o\n",
      "Transforming summaries document 52 with model gpt-4o\n",
      "Transforming summaries document 53 with model gpt-4o\n",
      "Transforming summaries document 54 with model gpt-4o\n",
      "Transforming summaries document 55 with model gpt-4o\n",
      "Transforming summaries document 56 with model gpt-4o\n",
      "Transforming summaries document 57 with model gpt-4o\n",
      "Transforming summaries document 58 with model gpt-4o\n",
      "Transforming summaries document 59 with model gpt-4o\n",
      "Transforming summaries document 60 with model gpt-4o\n",
      "Transforming summaries document 61 with model gpt-4o\n",
      "Transforming summaries document 62 with model gpt-4o\n",
      "Transforming summaries document 63 with model gpt-4o\n",
      "Transforming summaries document 64 with model gpt-4o\n",
      "Transforming summaries document 65 with model gpt-4o\n",
      "Transforming summaries document 66 with model gpt-4o\n",
      "Transforming summaries document 67 with model gpt-4o\n",
      "Transforming summaries document 68 with model gpt-4o\n",
      "Transforming summaries document 69 with model gpt-4o\n",
      "Transforming summaries document 70 with model gpt-4o\n",
      "Transforming summaries document 71 with model gpt-4o\n",
      "Transforming summaries document 72 with model gpt-4o\n",
      "Transforming summaries document 73 with model gpt-4o\n",
      "Transforming summaries document 74 with model gpt-4o\n",
      "Transforming summaries document 75 with model gpt-4o\n",
      "Transforming summaries document 76 with model gpt-4o\n",
      "Transforming summaries document 77 with model gpt-4o\n",
      "Transforming summaries document 78 with model gpt-4o\n",
      "Transforming summaries document 79 with model gpt-4o\n",
      "Transforming summaries document 80 with model gpt-4o\n",
      "Transforming summaries document 81 with model gpt-4o\n",
      "Transforming summaries document 82 with model gpt-4o\n",
      "Transforming summaries document 83 with model gpt-4o\n",
      "Transforming summaries document 84 with model gpt-4o\n",
      "Transforming summaries document 85 with model gpt-4o\n",
      "Transforming summaries document 86 with model gpt-4o\n",
      "Transforming summaries document 87 with model gpt-4o\n",
      "Transforming summaries document 88 with model gpt-4o\n",
      "Transforming summaries document 89 with model gpt-4o\n",
      "Transforming summaries document 90 with model gpt-4o\n",
      "Transforming summaries document 91 with model gpt-4o\n",
      "Transforming summaries document 92 with model gpt-4o\n",
      "Transforming summaries document 93 with model gpt-4o\n",
      "Transforming summaries document 94 with model gpt-4o\n",
      "Transforming summaries document 95 with model gpt-4o\n",
      "Transforming summaries document 96 with model gpt-4o\n",
      "Transforming summaries document 97 with model gpt-4o\n",
      "Transforming summaries document 98 with model gpt-4o\n",
      "Transforming summaries document 99 with model gpt-4o\n",
      "Transforming summaries document 100 with model gpt-4o\n",
      "Transforming summaries document 101 with model gpt-4o\n",
      "Transforming summaries document 102 with model gpt-4o\n",
      "Transforming summaries document 103 with model gpt-4o\n",
      "Transforming summaries document 104 with model gpt-4o\n",
      "Transforming summaries document 105 with model gpt-4o\n",
      "Transforming summaries document 106 with model gpt-4o\n",
      "Transforming summaries document 107 with model gpt-4o\n",
      "Transforming summaries document 108 with model gpt-4o\n",
      "Transforming summaries document 109 with model gpt-4o\n",
      "Transforming summaries document 110 with model gpt-4o\n",
      "Transforming summaries document 111 with model gpt-4o\n",
      "Transforming summaries document 112 with model gpt-4o\n",
      "Transforming summaries document 113 with model gpt-4o\n",
      "Transforming summaries document 114 with model gpt-4o\n",
      "Transforming summaries document 115 with model gpt-4o\n",
      "Transforming summaries document 116 with model gpt-4o\n",
      "Transforming summaries document 117 with model gpt-4o\n",
      "Transforming summaries document 118 with model gpt-4o\n",
      "Transforming summaries document 119 with model gpt-4o\n",
      "Transforming summaries document 120 with model gpt-4o\n",
      "Transforming summaries document 121 with model gpt-4o\n",
      "Transforming summaries document 122 with model gpt-4o\n",
      "Transforming summaries document 123 with model gpt-4o\n",
      "Transforming summaries document 124 with model gpt-4o\n",
      "Transforming summaries document 125 with model gpt-4o\n",
      "Transforming summaries document 126 with model gpt-4o\n",
      "Transforming summaries document 127 with model gpt-4o\n",
      "Transforming summaries document 128 with model gpt-4o\n",
      "Transforming summaries document 129 with model gpt-4o\n",
      "Transforming summaries document 130 with model gpt-4o\n",
      "Transforming summaries document 131 with model gpt-4o\n",
      "Transforming summaries document 132 with model gpt-4o\n",
      "Transforming summaries document 133 with model gpt-4o\n",
      "Transforming summaries document 134 with model gpt-4o\n",
      "Transforming summaries document 135 with model gpt-4o\n",
      "Transforming summaries document 136 with model gpt-4o\n",
      "Transforming summaries document 137 with model gpt-4o\n",
      "Transforming summaries document 138 with model gpt-4o\n",
      "Transforming summaries document 139 with model gpt-4o\n",
      "Transforming summaries document 140 with model gpt-4o\n",
      "Transforming summaries document 141 with model gpt-4o\n",
      "Transforming summaries document 142 with model gpt-4o\n",
      "Transforming summaries document 143 with model gpt-4o\n",
      "Transforming summaries document 144 with model gpt-4o\n",
      "Transforming summaries document 145 with model gpt-4o\n",
      "Transforming summaries document 146 with model gpt-4o\n",
      "Transforming summaries document 147 with model gpt-4o\n",
      "Transforming summaries document 148 with model gpt-4o\n",
      "Transforming summaries document 149 with model gpt-4o\n",
      "Transforming summaries document 150 with model gpt-4o\n",
      "Transforming summaries document 151 with model gpt-4o\n",
      "Transforming summaries document 152 with model gpt-4o\n",
      "Transforming summaries document 153 with model gpt-4o\n",
      "Transforming summaries document 154 with model gpt-4o\n",
      "Transforming summaries document 155 with model gpt-4o\n",
      "Transforming summaries document 156 with model gpt-4o\n",
      "Transforming summaries document 157 with model gpt-4o\n",
      "Transforming summaries document 158 with model gpt-4o\n",
      "Transforming summaries document 159 with model gpt-4o\n",
      "Transforming summaries document 160 with model gpt-4o\n",
      "Transforming summaries document 161 with model gpt-4o\n",
      "Transforming summaries document 162 with model gpt-4o\n",
      "Transforming summaries document 163 with model gpt-4o\n",
      "Transforming summaries document 164 with model gpt-4o\n",
      "Transforming summaries document 165 with model gpt-4o\n",
      "Transforming summaries document 166 with model gpt-4o\n",
      "Transforming summaries document 167 with model gpt-4o\n",
      "Transforming summaries document 168 with model gpt-4o\n",
      "Transforming summaries document 169 with model gpt-4o\n",
      "Transforming summaries document 170 with model gpt-4o\n",
      "Transforming summaries document 171 with model gpt-4o\n",
      "Transforming summaries document 172 with model gpt-4o\n",
      "Transforming summaries document 173 with model gpt-4o\n",
      "Transforming summaries document 174 with model gpt-4o\n",
      "Transforming summaries document 175 with model gpt-4o\n",
      "Transforming summaries document 176 with model gpt-4o\n",
      "Transforming summaries document 177 with model gpt-4o\n",
      "Transforming summaries document 178 with model gpt-4o\n",
      "Transforming summaries document 179 with model gpt-4o\n",
      "Writing summaries documents from model gpt-4o to file\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def transform_documents(chain, file):\n",
    "    if use_cached_transforms:\n",
    "        print(f\"Loading cached file {file}\")\n",
    "        with open(f\"cache/{llm_model}_{file}_documents.pickle\", \"rb\") as f:\n",
    "            result = pickle.load(f)\n",
    "        return result\n",
    "    else:\n",
    "        result = copy.deepcopy(split_documents)\n",
    "        for doc in result:\n",
    "            print(f\"Transforming {file} document {doc.metadata['index']} with model {llm_model}\")\n",
    "            doc.metadata[\"original_content\"] = copy.copy(doc.page_content)\n",
    "            doc.page_content = chain.run(doc.page_content)\n",
    "        print(f\"Writing {file} documents from model {llm_model} to file\")\n",
    "        with open(f\"cache/{llm_model}_{file}_documents.pickle\", \"wb\") as f:\n",
    "            pickle.dump(result, f)\n",
    "        return result\n",
    "\n",
    "question_documents = transform_documents(question_chain, \"questions\")\n",
    "answer_documents = transform_documents(answer_chain, \"answers\")\n",
    "summary_documents = transform_documents(summarize_chain, \"summaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = None\n",
    "\n",
    "if embedding_source == \"openai\":\n",
    "    embeddings = OpenAIEmbeddings(model=embeddings_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "def store(documents, collection_name):\n",
    "    Qdrant.from_documents(\n",
    "        documents,\n",
    "        url=\"http://localhost:6333\",\n",
    "        embedding=embeddings,\n",
    "        collection_name=collection_name,\n",
    "        force_recreate=True,\n",
    "    )\n",
    "\n",
    "pure_collection = f\"{embeddings_model}-{llm_model}-p\"\n",
    "question_collection = f\"{embeddings_model}-{llm_model}-q\"\n",
    "answer_collection = f\"{embeddings_model}-{llm_model}-a\"\n",
    "summary_collection = f\"{embeddings_model}-{llm_model}-s\"\n",
    "\n",
    "collections = [pure_collection, question_collection, answer_collection, summary_collection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings and store them in different collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "if reindex_documents:\n",
    "    store(split_documents, pure_collection)\n",
    "    store(question_documents, question_collection)\n",
    "    store(answer_documents, answer_collection)\n",
    "    store(summary_documents, summary_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with a query in the different indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Was mache ich, wenn ich meinen letzten Zug verpasst habe?\",\n",
    "    \"Nach wie vielen Jahren kann ich mein Notebook erneuern?\",\n",
    "    \"Was ist MITOD?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching text-embedding-ada-002-gpt-4o-p for Was mache ich, wenn ich meinen letzten Zug verpasst habe?\n",
      "Searching text-embedding-ada-002-gpt-4o-p for Nach wie vielen Jahren kann ich mein Notebook erneuern?\n",
      "Searching text-embedding-ada-002-gpt-4o-p for Was ist MITOD?\n",
      "Searching text-embedding-ada-002-gpt-4o-q for Was mache ich, wenn ich meinen letzten Zug verpasst habe?\n",
      "Searching text-embedding-ada-002-gpt-4o-q for Nach wie vielen Jahren kann ich mein Notebook erneuern?\n",
      "Searching text-embedding-ada-002-gpt-4o-q for Was ist MITOD?\n",
      "Searching text-embedding-ada-002-gpt-4o-a for Was mache ich, wenn ich meinen letzten Zug verpasst habe?\n",
      "Searching text-embedding-ada-002-gpt-4o-a for Nach wie vielen Jahren kann ich mein Notebook erneuern?\n",
      "Searching text-embedding-ada-002-gpt-4o-a for Was ist MITOD?\n",
      "Searching text-embedding-ada-002-gpt-4o-s for Was mache ich, wenn ich meinen letzten Zug verpasst habe?\n",
      "Searching text-embedding-ada-002-gpt-4o-s for Nach wie vielen Jahren kann ich mein Notebook erneuern?\n",
      "Searching text-embedding-ada-002-gpt-4o-s for Was ist MITOD?\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "def search(collection, query):\n",
    "    return Qdrant(client, collection, embeddings)._similarity_search_with_relevance_scores(query)\n",
    "\n",
    "collections = [pure_collection, question_collection, answer_collection, summary_collection]\n",
    "\n",
    "result_table = []\n",
    "result_table.append([\"Collection\"] + queries)\n",
    "\n",
    "for collection in collections:\n",
    "    row = []\n",
    "    for query in queries:\n",
    "        print(f\"Searching {collection} for {query}\")\n",
    "        search_results = search(collection, query)\n",
    "\n",
    "        row.append(\"\\n\".join([f\"{document.metadata['index']} - {score}\" for document, score in search_results]))\n",
    "\n",
    "    result_table.append([collection] + row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-------------------------------------------------------------+-----------------------------------------------------------+------------------+\n",
      "| Collection                      | Was mache ich, wenn ich meinen letzten Zug verpasst habe?   | Nach wie vielen Jahren kann ich mein Notebook erneuern?   | Was ist MITOD?   |\n",
      "+=================================+=============================================================+===========================================================+==================+\n",
      "| text-embedding-3-large-gpt-4o-p | 46 - 0.58883804                                             | 105 - 0.3691822                                           | 97 - 0.5132947   |\n",
      "|                                 | 48 - 0.45619273                                             | 33 - 0.36080652                                           | 96 - 0.3301171   |\n",
      "|                                 | 45 - 0.37149027                                             | 32 - 0.35150042                                           | 136 - 0.3039251  |\n",
      "|                                 | 47 - 0.3679158                                              | 104 - 0.33515233                                          | 25 - 0.2724043   |\n",
      "+---------------------------------+-------------------------------------------------------------+-----------------------------------------------------------+------------------+\n",
      "| text-embedding-3-large-gpt-4o-q | 46 - 0.6212136                                              | 105 - 0.39980996                                          | 97 - 0.51667285  |\n",
      "|                                 | 48 - 0.37809804                                             | 32 - 0.36348093                                           | 96 - 0.314003    |\n",
      "|                                 | 45 - 0.33756763                                             | 107 - 0.33075163                                          | 138 - 0.26675835 |\n",
      "|                                 | 49 - 0.33484697                                             | 104 - 0.32813346                                          | 119 - 0.26395792 |\n",
      "+---------------------------------+-------------------------------------------------------------+-----------------------------------------------------------+------------------+\n",
      "| text-embedding-3-large-gpt-4o-a | 46 - 0.69103867                                             | 33 - 0.36940724                                           | 97 - 0.36626965  |\n",
      "|                                 | 48 - 0.3818755                                              | 105 - 0.35639203                                          | 19 - 0.2735644   |\n",
      "|                                 | 45 - 0.3363611                                              | 32 - 0.34321746                                           | 136 - 0.2671081  |\n",
      "|                                 | 47 - 0.31609714                                             | 104 - 0.31548652                                          | 96 - 0.26552188  |\n",
      "+---------------------------------+-------------------------------------------------------------+-----------------------------------------------------------+------------------+\n",
      "| text-embedding-3-large-gpt-4o-s | 46 - 0.60631895                                             | 33 - 0.46263397                                           | 97 - 0.39856604  |\n",
      "|                                 | 48 - 0.43144882                                             | 105 - 0.35534406                                          | 136 - 0.32399094 |\n",
      "|                                 | 45 - 0.3773084                                              | 32 - 0.34942812                                           | 96 - 0.29185927  |\n",
      "|                                 | 50 - 0.33240083                                             | 104 - 0.31167895                                          | 16 - 0.29144782  |\n",
      "+---------------------------------+-------------------------------------------------------------+-----------------------------------------------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(result_table, tablefmt=\"grid\", headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To check a result, put the index in the following cell and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_Kommentar von Ingo: Da die Frage öfters kommt, schreibe ich mal kurz die Info zu den von mir bevorzugten Schutzfolien für iPads. ;)_  \n",
      "Vorweg: da das iPad seit Jahren nahezu mein Hauptarbeitsgerät ist, habe ich ohne Ende unterschiedliche Folien und Schutzgläser ausprobiert - die Kombination unten ist für mich absolut die Beste. (Und zwar bei weiten ... die schlechtesten Folien sind - auch wenn sie dreimal so teuer sind - teilweise sowas von extrem gruselig. Und obwohl ich auf dem iPhone “Panzerglas” besser finde als Folien, finde ich sie beim iPad einfach zu dick und störend beim Schreibfluss.)  \n",
      "Generell: die Front-Folien sind für mich immer matt, da sie so für mich ein viel besseres Schreibgefühl liefern - und da das iPad für mich Arbeitsgerät ist, kann ich mit der etwas schlechteren Bildqualität (verminderter Kontrast durch beabsichtigte Streuung/Mattierung der Folie) sehr, sehr gut leben.  \n",
      "Ich verwende auch eine Folie für die Rückseite. Diese ist etwas dicker und - vor allem - griffig. Diese Folie verwende ich, da ich das iPad dann auch aus dem Cover/Keyboard-Cover rausnehmen kann, ohne dauernd zu befürchten, dass es verkratzt. Da diese Folie sehr griffig ist, kann ich beim 11\"er damit auch problemlos mit einer Hand lesen ohne dass ich das iPad wirklich fest greifen muss ...  \n",
      "Folien für’s 11\" iPad Pro 2018 (aktuelle Gen 3)  \n",
      "* Front: Mumbi matt, [https://www.amazon.de/gp/product/B07K26YDS7](https://www.amazon.de/gp/product/B07K26YDS7)\n",
      "* Back: Arktis Final Protection, [https://www.amazon.de/gp/product/B07KJBRDPF](https://www.amazon.de/gp/product/B07KJBRDPF)  \n",
      "Folien für 12.9\" iPad Pro 2018 (aktuelle Gen 3)  \n",
      "* Front: Mumbi matt, [https://www.amazon.de/gp/product/B07K27LP9J](https://www.amazon.de/gp/product/B07K27LP9J)\n",
      "* Back: Arktis Final Protection, [https://www.amazon.de/gp/product/B07KJNPKZX](https://www.amazon.de/gp/product/B07KJNPKZX)  \n",
      "### Hardware Life Cycle  \n",
      "Weil wir mit der Zeit gehen wollen und mit modernen Technologien arbeiten, kann die Hardware regelmäßig erneuert werden. Aktuell haben wir für folgende Geräte folgende Life Cycles, gerechnet ab dem Zeitpunkt der Übergabe an dich:  \n",
      "* Phone - alle 2 Jahre\n",
      "* Tablet - alle 2 Jahre\n",
      "* Notebook - alle 3 Jahre  \n",
      "In Sonderfällen kann auch mal was außerhalb gekauft werden, z. B. wenn ein Laptop extreme Verbesserungen mit sich bringt. Das sollte aber vorher abgesprochen werden.  \n",
      "### Zutrittskarte Karlsruhe  \n",
      "Wer in Karlsruhe arbeitet, bekommt eine Zutrittskarte. Mit dieser Karte kommt man rund um die Uhr ins Gebäude oder in die Tiefgarage.  \n",
      "> Bei Verlust der Karte bitte umgehend das Office Management informieren, wir lassen sie sperren und geben dir eine neue.  \n",
      "### Parkplätze Karlsruhe  \n",
      "Wir haben in Karlsruhe eine Tiefgarage mit 5 Thinktecture-Stellplätzen, in der jeder parken kann. Unsere Parkplätze sind entsprechend gekennzeichnet. Reservierungen gibt es nicht. Hier gilt das Motto: Wer zuerst kommt, parkt zuerst. Ist die Garage voll belegt, gibt es in der Regel noch Plätze in der direkten Nachbarschaft.  \n",
      "Die Einfahrtshöhe in die Tiefgarage beträgt nach Angaben der Hausverwaltung 2,00 m.  \n",
      "### Ladestation  \n",
      "An einem der Parkplätze in der Tiefgarage haben wir eine Ladestation für Elektroautos, an denen ihr kostenlos aufladen könnt. Schlüssel und Karte dafür dann bitte beim Office Management geben lassen.\n",
      "\n",
      "\n",
      "{'Header 1': 'Büro- und Geschäftsausstattung', 'Header 2': 'Infos zu matten Folien für iPads', 'source': 'C:\\\\Dev\\\\tt\\\\tt-readme\\\\best-practices\\\\arbeiten-bei-tt\\\\buero-und-geschaeftsausstattung.md', 'index': 33, 'original_content': '_Kommentar von Ingo: Da die Frage öfters kommt, schreibe ich mal kurz die Info zu den von mir bevorzugten Schutzfolien für iPads. ;)_  \\nVorweg: da das iPad seit Jahren nahezu mein Hauptarbeitsgerät ist, habe ich ohne Ende unterschiedliche Folien und Schutzgläser ausprobiert - die Kombination unten ist für mich absolut die Beste. (Und zwar bei weiten ... die schlechtesten Folien sind - auch wenn sie dreimal so teuer sind - teilweise sowas von extrem gruselig. Und obwohl ich auf dem iPhone “Panzerglas” besser finde als Folien, finde ich sie beim iPad einfach zu dick und störend beim Schreibfluss.)  \\nGenerell: die Front-Folien sind für mich immer matt, da sie so für mich ein viel besseres Schreibgefühl liefern - und da das iPad für mich Arbeitsgerät ist, kann ich mit der etwas schlechteren Bildqualität (verminderter Kontrast durch beabsichtigte Streuung/Mattierung der Folie) sehr, sehr gut leben.  \\nIch verwende auch eine Folie für die Rückseite. Diese ist etwas dicker und - vor allem - griffig. Diese Folie verwende ich, da ich das iPad dann auch aus dem Cover/Keyboard-Cover rausnehmen kann, ohne dauernd zu befürchten, dass es verkratzt. Da diese Folie sehr griffig ist, kann ich beim 11\"er damit auch problemlos mit einer Hand lesen ohne dass ich das iPad wirklich fest greifen muss ...  \\nFolien für’s 11\" iPad Pro 2018 (aktuelle Gen 3)  \\n* Front: Mumbi matt, [https://www.amazon.de/gp/product/B07K26YDS7](https://www.amazon.de/gp/product/B07K26YDS7)\\n* Back: Arktis Final Protection, [https://www.amazon.de/gp/product/B07KJBRDPF](https://www.amazon.de/gp/product/B07KJBRDPF)  \\nFolien für 12.9\" iPad Pro 2018 (aktuelle Gen 3)  \\n* Front: Mumbi matt, [https://www.amazon.de/gp/product/B07K27LP9J](https://www.amazon.de/gp/product/B07K27LP9J)\\n* Back: Arktis Final Protection, [https://www.amazon.de/gp/product/B07KJNPKZX](https://www.amazon.de/gp/product/B07KJNPKZX)  \\n### Hardware Life Cycle  \\nWeil wir mit der Zeit gehen wollen und mit modernen Technologien arbeiten, kann die Hardware regelmäßig erneuert werden. Aktuell haben wir für folgende Geräte folgende Life Cycles, gerechnet ab dem Zeitpunkt der Übergabe an dich:  \\n* Phone - alle 2 Jahre\\n* Tablet - alle 2 Jahre\\n* Notebook - alle 3 Jahre  \\nIn Sonderfällen kann auch mal was außerhalb gekauft werden, z. B. wenn ein Laptop extreme Verbesserungen mit sich bringt. Das sollte aber vorher abgesprochen werden.  \\n### Zutrittskarte Karlsruhe  \\nWer in Karlsruhe arbeitet, bekommt eine Zutrittskarte. Mit dieser Karte kommt man rund um die Uhr ins Gebäude oder in die Tiefgarage.  \\n> Bei Verlust der Karte bitte umgehend das Office Management informieren, wir lassen sie sperren und geben dir eine neue.  \\n### Parkplätze Karlsruhe  \\nWir haben in Karlsruhe eine Tiefgarage mit 5 Thinktecture-Stellplätzen, in der jeder parken kann. Unsere Parkplätze sind entsprechend gekennzeichnet. Reservierungen gibt es nicht. Hier gilt das Motto: Wer zuerst kommt, parkt zuerst. Ist die Garage voll belegt, gibt es in der Regel noch Plätze in der direkten Nachbarschaft.  \\nDie Einfahrtshöhe in die Tiefgarage beträgt nach Angaben der Hausverwaltung 2,00 m.  \\n### Ladestation  \\nAn einem der Parkplätze in der Tiefgarage haben wir eine Ladestation für Elektroautos, an denen ihr kostenlos aufladen könnt. Schlüssel und Karte dafür dann bitte beim Office Management geben lassen.'}\n",
      "\n",
      "\n",
      "Questions: 1. Welche Schutzfolien empfiehlt Ingo für das 11\" iPad Pro 2018 und das 12.9\" iPad Pro 2018?\n",
      "2. Warum bevorzugt Ingo matte Front-Folien für sein iPad?\n",
      "3. Welche Vorteile bietet die von Ingo verwendete Rückseitenfolie für das iPad?\n",
      "\n",
      "\n",
      "Answers: Der Text beantwortet mehrere Fragen: Ingo gibt Empfehlungen für Schutzfolien für iPads, die er aufgrund seiner umfangreichen Nutzungserfahrung bevorzugt. Zudem werden Informationen zum Hardware-Lebenszyklus, Zutrittskarten, Parkplätzen und einer Ladestation für Elektroautos in Karlsruhe bereitgestellt.\n",
      "\n",
      "\n",
      "Summary: Ingo hat zahlreiche Schutzfolien für iPads getestet und empfiehlt für die Frontseite matte Folien, da sie ein besseres Schreibgefühl bieten, auch wenn die Bildqualität etwas leidet. Für die Rückseite bevorzugt er griffige, dickere Folien, um das iPad vor Kratzern zu schützen und es sicherer halten zu können. Für das 11\" iPad Pro 2018 empfiehlt er die Mumbi matte Folie für die Front und die Arktis Final Protection für die Rückseite. Dasselbe gilt für das 12.9\" iPad Pro 2018.\n",
      "\n",
      "Zusätzlich gibt es Informationen zu den Hardware-Lebenszyklen bei Thinktecture: Telefone und Tablets werden alle 2 Jahre, Notebooks alle 3 Jahre erneuert. Zutrittskarten für das Büro in Karlsruhe ermöglichen rund um die Uhr Zugang und bei Verlust sollte das Office Management informiert werden. Es gibt fünf Parkplätze in der Tiefgarage, die nach dem Prinzip \"Wer zuerst kommt, parkt zuerst\" genutzt werden können. Eine Ladestation für Elektroautos steht ebenfalls zur Verfügung, deren Schlüssel und Karte beim Office Management erhältlich sind.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "found_index = 33\n",
    "\n",
    "# find the document with the metadata index of the found_index variable\n",
    "\n",
    "found_document = None\n",
    "for doc in split_documents:\n",
    "    if doc.metadata[\"index\"] == found_index:\n",
    "        found_document = doc\n",
    "        break\n",
    "\n",
    "print(f'{found_document.page_content}\\n\\n')\n",
    "print(f'{found_document.metadata}\\n\\n')\n",
    "\n",
    "for doc in question_documents:\n",
    "    if doc.metadata[\"index\"] == found_index:\n",
    "        found_document = doc\n",
    "        break\n",
    "\n",
    "print(f\"Questions: {found_document.page_content}\\n\\n\")\n",
    "\n",
    "for doc in answer_documents:\n",
    "    if doc.metadata[\"index\"] == found_index:\n",
    "        found_document = doc\n",
    "        break\n",
    "\n",
    "print(f\"Answers: {found_document.page_content}\\n\\n\")\n",
    "\n",
    "for doc in summary_documents:\n",
    "    if doc.metadata[\"index\"] == found_index:\n",
    "        found_document = doc\n",
    "        break\n",
    "\n",
    "print(f\"Summary: {found_document.page_content}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG (Teaser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In den bereitgestellten Informationen gibt es keine Angaben darüber, nach wie vielen Jahren ein Notebook erneuert werden kann. Die Informationen beziehen sich ausschließlich auf die Nutzung und Verwaltung der BahnCard First 50 und nicht auf die IT-Ausstattung oder ähnliche firmeninterne Vorgänge.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# Document\n",
    "found_index = 31\n",
    "found_document = None\n",
    "for doc in split_documents:\n",
    "    if doc.metadata[\"index\"] == found_index:\n",
    "        found_document = doc\n",
    "        break\n",
    "\n",
    "query = \"Nach wie vielen Jahren kann ich mein Notebook erneuern?\"\n",
    "\n",
    "# Prompt\n",
    "template = f\"\"\"Beantworte die Frage nur aufgrund der folgenenden Informationen:\n",
    "{found_document.page_content}\n",
    "\n",
    "Frage: {query}\n",
    "\"\"\"\n",
    "\n",
    "# RAG chain\n",
    "chain = (\n",
    "    ChatPromptTemplate.from_template(template)\n",
    "    | ChatOpenAI(model_name = 'gpt-4-1106-preview')\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
